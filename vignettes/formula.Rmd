---
title: "The Formula of Random-Effect Latent Variable Model"
author: "Ren-Huai Huang"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## 1. Latent Variable Model

$X_m =  \mu_m + l_m F + \epsilon_m$   

$\epsilon_m \sim N(0,\sigma^2)$   

$F \sim N(0,1)  \hspace{71pt}$    


- $X_m$ :  The standardized observed vriable
- $\mu_m$ : The offset to the mean
- $l_m$ : The loading of the latent variable $F$
- $F$: The latent variable
- $\epsilon_m$: Normal distributed error 
- Example: suppose we have a set of 4 observed variables ($m = 1,2,3,4$)  
$X_1 =  \mu_1 + l_1 F + \epsilon_1$  
$X_2 =  \mu_2 + l_2 F + \epsilon_2$  
$X_3 =  \mu_3 + l_3 F + \epsilon_3$  
$X_4 =  \mu_4 + l_4 F + \epsilon_4$  
$X_5 =  \mu_5 + l_5 F + \epsilon_5$  
$X_6 =  \mu_6 + l_6 F + \epsilon_6$  
$X_7 =  \mu_7 + l_7 F + \epsilon_7$  

## 2. Weighted likelihood (L) & log likelihood(LL) 

**For each hospital $h$:**  
$L^{(h)} = \prod_{m=1}^7 L( X_{m}^{(h)}, \; mean=\mu_{m} + l_{m} * F^{(h)}, sd = \sigma_{m})^{w_m^{(h)}} \hspace{35pt}$  

or

$LL^{(h)} = \sum_{m=1}^7 (w_m^{(h)} * \log( L( X_{m}^{(h)}, \; mean=\mu_{m} + l_{m} * F^{(h)}, sd = \sigma_{m}))) \hspace{35pt}$  


<br />
**For all hospitals $(h= 1,2,3,...,H)$:** 

$L^{(total)} = \prod_{h=1}^H \prod_{m=1}^7 L( X_{m}^{(h)}, \; mean=\mu_{m} + l_{m} * F^{(h)}, sd = \sigma_{m})^{w_m^{(h)}} \hspace{35pt}$  

or

$LL^{(total)} = \sum_{h=1}^H \sum_{m=1}^7 (w_m^{(h)} * \log( L( X_{m}^{(h)}, \; mean=\mu_{m} + l_{m} * F^{(h)}, sd = \sigma_{m}))) \hspace{35pt}$  

- $L$: normal likelihood function 
  

## 3. Random Effect Log Likelihood
$Random^{(h)} = \log(L(F^{(h)}, mean = 0, sd = 1))$

## 4. The Random-Effect Latent Variable Model (Objective Function)     

**The joint log likelihood for one of the observation h**   

Joint likelihood   
$Joint_{L}^{(h)} = L^{(h)} L(F^{(h)}, mean = 0, sd = 1)$    
<center>*or*</center>    

$Joint_L^{(h)} = \prod_{m=1}^7 L( X_{m}^{(h)}, \; mean=\mu_{m} + l_{m} * F^{(h)}, sd = \sigma_{m})^{w_m^{(h)}} L(F^{(h)}, mean = 0, sd = 1)$ 

<center>*or*</center>    
Joint log likelihood    
$Joint_{LL}^{(h)} = LL^{(h)} + Random^{(h)}$  
<center>*or*</center>  

$Joint_{LL}^{(h)} = \sum_{m=1}^7 (w_m^{(h)} * \log( L( X_{m}^{(h)}, \; mean=\mu_{m} + l_{m} * F^{(h)}, sd = \sigma_{m}))) + \log(L(F^{(h)}, mean = 0, sd = 1))$  



<br />
**The joint log likelihood for all observations $(h = 1,2,3,...,H)$**  

$Joint^{(Total)} = \sum_{h=1}^{H}(LL^{(h)} + Random^{(h)}) \hspace{40pt}$  

- $H$: The total number of observations  

## 5. The marginal distribution in a mixed model:

$m^{(h)}(\theta) = \int L^{h}L(F^{(h)},mean=0,sd=1)dF^{(h)}$

## 6. The objective function
$f(\theta) = -\log\prod_{h=1}^{H}m^{(h)}(\theta)$

## 7 Quadrature approximation:   
#### 7.1 Gaussian-Hermite quadrature rule:  

$\int_{}^{} \exp(-x^2)f(x)\mathrm{dx} \approx \sum_{i=1}^{N}w_{i}f(x_{i})$ <br /> <br />

Consider a function $h(y)$, where the variable $y$ is Normally districubted: $y \sim N(\mu,\sigma^2)$. The expectation of $h(y)$ corresponds to the follwoing integral:   

$\int \cfrac{1}{\sigma \sqrt{2 \pi} } \exp(- \cfrac{(a-\hat{u})^2}{2 \sigma ^2}) h(a) \mathrm{da} \hspace{20pt} \\$ #
$substitute \; z = \cfrac{a-\hat{u}}{\sqrt{2} \sigma} \to a = \hat{u} + \sqrt{2} \sigma z$

$= \int \cfrac{1}{\sigma \sqrt{2 \pi} } \exp(- \cfrac{(a-\hat{u})^2}{2 \sigma ^2}) h(\hat{u} + \sqrt{2} \sigma z) \mathrm{d}(\hat{u} + \sqrt{2} \sigma z)$

$= \int \cfrac{1}{\sqrt{\pi}}\exp(-z^2)h(\sqrt{2}\sigma z + \mu) \mathrm{dz}\\$

$\approx \cfrac{1}{\sqrt{\pi}} \sum_{i=1}^{N}w_i\cdot h(\sqrt{2}\sigma z_i + \mu)$

Ref: [Gauss Hermite_quadrature](https://en.wikipedia.org/wiki/Gauss-Hermite_quadrature)

#### 7.2  Marginal probability of mixed effect with Gauss-Hermite quadrature approximation for hospital $h$:

$\int p(y_h)q(u)\mathrm{du}$  

$= \int p(y_h)q(a)\mathrm{da} \hspace{85pt}$  # Substitute variable $u \rightarrow a$

$= \int p(y_h)q(a) \exp(z^2) \exp(-z^2) \mathrm{da} \hspace{12pt}$  # Add $\exp(z^2)\exp(-z^2) \hspace{15pt} ( = 1)$

$= \int p(y_h)q(a) \exp(z^2) \exp(-z^2) \mathrm{d}(\hat{u} + \sqrt{2} \sigma z)$  # Substitute $a$ with $\hat{u} + \sqrt{2} \sigma z$

$= \sqrt{2} \sigma \int p(y_h)q(a) \exp(z^2) \exp(-z^2) \mathrm{dz}$  # Simpflify  


$\approx \sqrt{2} \sigma \sum_{i=1}^{N} w_i \cdot p(y^h) q(a_i) \exp(z_i^2)$

- $a_i = \hat{u} + \sqrt{2} \sigma z_i$  
- $\sigma = \cfrac{1}{\sqrt{f^{''}(- \log (p(y_h)q(u)))}}$, $f^{''}$ is the second derivative of $f(u) = - \log (p(y_h)q(u)))$ 
- $z_i,w_i (i = 1,...N): \text{the standard Gauss-Hermite abscissas and weights}$

- $f^{'} = \cfrac{\partial}{\partial{u}} (-\log[p(y^h)q(u)])$
$= u_h - \sum w_m^h\cfrac{y_m^h-(\mu_m + l _m \cdot u^h)}{\sigma _m^2} \cdot l_m$

- $f^{''} = \cfrac{\partial{^{2}}}{\partial{u{^{2}}}} (-\log[p(y^h)q(u^h)])$
$= 1 + \sum w_m^h\cdot \cfrac{l _m ^2}{\sigma _m ^2}$


## 8. The corresponding SAS Code  
    proc nlmixed data=input tech=dbldog qpoints=30 noad;
        parms mu1-mu7=0;

        array x{*}      x1-x7;
        array mu{*}     mu1-mu7;
        array fl{*}     fl1-fl7;
        array loglik{*} loglik1-loglik7;
        array w{*}      w1-w7;
        array err{*}    err1-err7;
        totloglik = 0;
        
        do i=1 to 5; 
	        if x{i} = . then loglik{i}= 0;
	           else loglik{i} = w{i} * log(pdf('normal', x{i}, mu{i}+fl{i}*lv, err{i})); 
            totloglik = loglik{i} + totloglik;
        end;

        model   id ~ general(totloglik); 
        random  lv ~ normal(0, 1) subject= id;
        
        ods output ParameterEstimates=ParEst;
        predict lv out=Pred; 
    run;






